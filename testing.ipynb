{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llFZ_k4F2Hpr"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install pydicom SimpleITK matplotlib kaggle\n",
        "\n",
        "# Set up Kaggle authentication\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json file\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the RSNA dataset\n",
        "!kaggle competitions download -c rsna-2024-lumbar-spine-degenerative-classification\n",
        "!unzip -q rsna-2024-lumbar-spine-degenerative-classification.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading and Visualizing DICOM files"
      ],
      "metadata": {
        "id": "Q0TjqYFH2R-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n"
      ],
      "metadata": {
        "id": "9pHprU3k-DyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n"
      ],
      "metadata": {
        "id": "mfvZTfL1-PWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Set the path to the unzipped data folder\n",
        "data_path = \"/content/train_images\"\n",
        "\n",
        "# Recursively search for all files in subdirectories\n",
        "dicom_files = []\n",
        "for dirpath, _, filenames in os.walk(data_path):\n",
        "    for f in filenames:\n",
        "        dicom_files.append(os.path.join(dirpath, f))\n",
        "\n",
        "# Check if files are found\n",
        "print(f\"Number of DICOM files found: {len(dicom_files)}\")\n",
        "\n",
        "# Try reading the first valid DICOM file\n",
        "if dicom_files:\n",
        "    for file in dicom_files:\n",
        "        try:\n",
        "            # Read the DICOM file\n",
        "            dicom_image = pydicom.dcmread(file)\n",
        "\n",
        "            # Visualize the DICOM image using grayscale\n",
        "            plt.imshow(dicom_image.pixel_array, cmap=plt.cm.bone)\n",
        "            plt.title(f\"File: {file}\")\n",
        "            plt.show()\n",
        "\n",
        "            # Stop after successfully loading one image\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file}: {e}\")\n",
        "else:\n",
        "    print(\"No DICOM files found.\")\n"
      ],
      "metadata": {
        "id": "HdsgLFiv2Pw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Coordinates and Metadata"
      ],
      "metadata": {
        "id": "iFAhnofa2d0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract patient metadata and image properties from the loaded DICOM image\n",
        "\n",
        "# Use .get() to avoid errors if the attribute doesn't exist\n",
        "patient_id = dicom_image.PatientID\n",
        "study_date = dicom_image.get(\"StudyDate\", \"Study Date not available\")\n",
        "modality = dicom_image.get(\"Modality\", \"Modality not available\")\n",
        "image_position = dicom_image.get(\"ImagePositionPatient\", \"Image Position not available\")\n",
        "image_orientation = dicom_image.get(\"ImageOrientationPatient\", \"Image Orientation not available\")\n",
        "\n",
        "# Print the metadata\n",
        "print(f\"Patient ID: {patient_id}\")\n",
        "print(f\"Study Date: {study_date}\")\n",
        "print(f\"Modality: {modality}\")\n",
        "print(f\"Image Position (Patient): {image_position}\")\n",
        "print(f\"Image Orientation (Patient): {image_orientation}\")\n",
        "\n",
        "# Access pixel spacing (spacing between image pixels)\n",
        "pixel_spacing = dicom_image.get(\"PixelSpacing\", \"Pixel Spacing information not available\")\n",
        "print(f\"Pixel Spacing: {pixel_spacing}\")\n"
      ],
      "metadata": {
        "id": "nLPvWoO82eVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping Labels to Coordinates"
      ],
      "metadata": {
        "id": "V5q4h0952iWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file that contains the labels\n",
        "labels_df = pd.read_csv('/content/train.csv')  # Replace with the actual path to your CSV file\n",
        "\n",
        "# Ensure both PatientID and study_id are in the same format (string)\n",
        "labels_df['study_id'] = labels_df['study_id'].astype(str)\n",
        "patient_id = str(dicom_image.PatientID)\n",
        "\n",
        "# Attempt to find the corresponding label row in the DataFrame\n",
        "label_row = labels_df.loc[labels_df['study_id'] == patient_id]\n",
        "\n",
        "# Check if a matching row is found\n",
        "if not label_row.empty:\n",
        "    # Extract the spinal canal stenosis label for L1-L2\n",
        "    stenosis_label = label_row['spinal_canal_stenosis_l1_l2'].values[0]\n",
        "    print(f\"Spinal Canal Stenosis L1-L2: {stenosis_label}\")\n",
        "else:\n",
        "    print(f\"No matching label found for Patient ID: {patient_id}\")\n"
      ],
      "metadata": {
        "id": "tkL1yBFcB-PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Labeled Areas"
      ],
      "metadata": {
        "id": "_FKlichq2s2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to overlay labels on DICOM images\n",
        "def overlay_label(image, label_text, position):\n",
        "    plt.imshow(image, cmap=plt.cm.bone)\n",
        "    plt.text(position[0], position[1], label_text, color=\"red\", fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "# Example: Visualize spinal canal stenosis label on the MRI\n",
        "image = dicom_image.pixel_array\n",
        "overlay_label(image, f\"Stenosis L1-L2: {stenosis_label}\", (50, 50))\n"
      ],
      "metadata": {
        "id": "9LWT7o5k2r8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterating Over Multiple DICOM Files"
      ],
      "metadata": {
        "id": "00BmZsv5_Fnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to load DICOM files, apply labels, and plot\n",
        "def process_dicom_with_labels(study_id, series_id, instance_number, label_data):\n",
        "    dicom_path = f'/content/train_images/{study_id}/{series_id}/{instance_number}.dcm'\n",
        "\n",
        "    # Check if DICOM file exists\n",
        "    if os.path.exists(dicom_path):\n",
        "        # Load DICOM file\n",
        "        dicom_image = pydicom.dcmread(dicom_path)\n",
        "\n",
        "        # Visualize DICOM image with condition markings\n",
        "        plt.imshow(dicom_image.pixel_array, cmap=plt.cm.bone)\n",
        "\n",
        "        # Filter relevant labels for the current image\n",
        "        current_labels = label_data[(label_data['study_id'] == study_id) &\n",
        "                                    (label_data['series_id'] == series_id) &\n",
        "                                    (label_data['instance_number'] == instance_number)]\n",
        "\n",
        "        # Plot each label on the DICOM image\n",
        "        for _, row in current_labels.iterrows():\n",
        "            x, y = row['x'], row['y']\n",
        "            condition = row['condition']\n",
        "            plt.scatter(x, y, color='red', s=50)\n",
        "            plt.text(x, y, condition, color='red', fontsize=12)\n",
        "\n",
        "        # Display the image with annotations\n",
        "        plt.title(f'DICOM Image for Study {study_id}, Series {series_id}')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"File {dicom_path} not found.\")\n",
        "\n",
        "# Function to iterate over multiple studies and series\n",
        "def process_multiple_dicoms(label_data, limit=10):\n",
        "    # Check if the necessary columns exist in the dataset\n",
        "    required_columns = ['study_id', 'series_id', 'instance_number']\n",
        "    if not all(col in label_data.columns for col in required_columns):\n",
        "        print(\"One or more required columns are missing. Please check the dataset.\")\n",
        "        return\n",
        "\n",
        "    # Group the labels by study_id, series_id, and instance_number\n",
        "    grouped = label_data.groupby(['study_id', 'series_id', 'instance_number'])\n",
        "\n",
        "    # Iterate through each unique combination and process the corresponding DICOM file\n",
        "    count = 0\n",
        "    for (study_id, series_id, instance_number), _ in grouped:\n",
        "        process_dicom_with_labels(study_id, series_id, instance_number, label_data)\n",
        "        count += 1\n",
        "        if count >= limit:  # Limit the number of processed files for testing\n",
        "            break\n",
        "\n",
        "# Call the function to process multiple DICOM files (limit to 10 for testing)\n",
        "process_multiple_dicoms(labels_df, limit=10)\n"
      ],
      "metadata": {
        "id": "w8yDncfq_FTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL"
      ],
      "metadata": {
        "id": "VnRTVvAA3jsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CNN Model"
      ],
      "metadata": {
        "id": "g3-OqYW-3obg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, channels)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "9gMVcamy3lpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the Model"
      ],
      "metadata": {
        "id": "zV0jQtPn3r0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jT9cad_q3tzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "2mwTdsW73v-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n"
      ],
      "metadata": {
        "id": "yoiiOvSP36OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Grad-CAM (Class Activation Mapping)"
      ],
      "metadata": {
        "id": "G2EMhlud38ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_layer_output, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    # Compute the gradients of the output for the predicted class wrt to the conv layer\n",
        "    grads = tape.gradient(class_channel, conv_layer_output)\n",
        "\n",
        "    # Compute the guided gradients (pooled gradients)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel in the feature map array by the \"importance\" of the channel\n",
        "    conv_layer_output = conv_layer_output[0]\n",
        "    heatmap = conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize the heatmap between 0 and 1 for better visualization\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Example usage: Generating heatmap for a sample input\n",
        "image_input = np.expand_dims(dicom.pixel_array, axis=0)  # Add batch dimension\n",
        "last_conv_layer_name = \"conv2d_2\"  # Change this to the last convolutional layer in your model\n",
        "\n",
        "heatmap = make_gradcam_heatmap(image_input, model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap on top of original image\n",
        "def display_gradcam(heatmap, image, alpha=0.4):\n",
        "    # Rescale heatmap to image size\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = np.resize(heatmap, (image.shape[0], image.shape[1]))\n",
        "\n",
        "    # Convert to RGB format\n",
        "    heatmap = plt.cm.jet(heatmap)[:, :, :3]\n",
        "    superimposed_img = heatmap * alpha + image\n",
        "\n",
        "    # Display the image with heatmap overlay\n",
        "    plt.imshow(superimposed_img, cmap='bone')\n",
        "    plt.show()\n",
        "\n",
        "display_gradcam(heatmap, dicom.pixel_array)\n"
      ],
      "metadata": {
        "id": "J7gNuCGm4McH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explainable AI (XAI) with Grad-CAM"
      ],
      "metadata": {
        "id": "qG_ETSYQ2wSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have trained a CNN model\n",
        "model = load_model('path_to_model.h5')\n",
        "\n",
        "def grad_cam(model, img_array, layer_name=\"conv5_block3_out\"):\n",
        "    # Create gradient tape and get model predictions\n",
        "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, np.argmax(predictions)]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    grad_cam_output = np.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Overlay Grad-CAM on the original image\n",
        "    heatmap = np.maximum(grad_cam_output, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    return heatmap\n",
        "\n",
        "# Generate Grad-CAM heatmap for a sample image\n",
        "image_input = np.expand_dims(dicom.pixel_array, axis=0)\n",
        "heatmap = grad_cam(model, image_input)\n",
        "\n",
        "# Display heatmap overlay\n",
        "plt.imshow(dicom.pixel_array, cmap=plt.cm.bone)\n",
        "plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap\n",
        "plt.title(\"Grad-CAM Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iIZxM-hy2y_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d6tyNISAf-bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mKu5f3N2f-Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Display the column names\n",
        "print(labels_df.columns)\n"
      ],
      "metadata": {
        "id": "aloGBJX8GRSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV file containing labels\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Ensure both the patient_id and study_id in the labels file are strings\n",
        "labels_df['study_id'] = labels_df['study_id'].astype(str)\n",
        "\n",
        "# Define the root directory where DICOM files are stored\n",
        "dicom_root_dir = '/content/train_images/'\n",
        "\n",
        "# Step 2: Iterate through the DataFrame to dynamically load the DICOM files and annotate them\n",
        "for _, row in labels_df.iterrows():\n",
        "    study_id = row['study_id']\n",
        "\n",
        "    # Assuming the DICOM file path is structured as \"/content/train_images/{study_id}/image.dcm\"\n",
        "    dicom_folder = os.path.join(dicom_root_dir, study_id)\n",
        "\n",
        "    # Find any DICOM files in the folder\n",
        "    dicom_files = [f for f in os.listdir(dicom_folder) if f.endswith('.dcm')]\n",
        "\n",
        "    # Iterate through DICOM files if they exist\n",
        "    for dicom_file in dicom_files:\n",
        "        dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "        # Check if the DICOM file exists and load it\n",
        "        if os.path.exists(dicom_path):\n",
        "            dicom_image = pydicom.dcmread(dicom_path)\n",
        "\n",
        "            # Extract patient ID from DICOM (optional, as we're using `study_id`)\n",
        "            patient_id = dicom_image.PatientID\n",
        "\n",
        "            # Annotate based on spinal canal stenosis\n",
        "            stenosis_l1_l2 = row['spinal_canal_stenosis_l1_l2']\n",
        "            stenosis_l2_l3 = row['spinal_canal_stenosis_l2_l3']\n",
        "\n",
        "            # (More conditions can be extracted similarly...)\n",
        "\n",
        "            # Step 3: Display or annotate the DICOM image (example of annotation)\n",
        "            pixel_array = dicom_image.pixel_array\n",
        "            normalized_image = cv2.normalize(pixel_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "            colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Example: Display condition on the image\n",
        "            cv2.putText(colored_image, f'L1-L2 Stenosis: {stenosis_l1_l2}', (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "            cv2.putText(colored_image, f'L2-L3 Stenosis: {stenosis_l2_l3}', (10, 60),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "            # Step 4: Display the annotated image\n",
        "            plt.imshow(colored_image, cmap='gray')\n",
        "            plt.title(f\"Annotated DICOM Image for Study ID: {study_id}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Optionally, save the annotated image\n",
        "            output_path = f'annotated_dicom_image_{study_id}_{dicom_file}.png'\n",
        "            cv2.imwrite(output_path, colored_image)\n",
        "        else:\n",
        "            print(f\"DICOM file not found: {dicom_path}\")\n"
      ],
      "metadata": {
        "id": "I7N6bYssf-A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV files\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "series_descriptions_df = pd.read_csv('/content/train_series_descriptions.csv')\n",
        "label_coordinates_df = pd.read_csv('/content/train_label_coordinates.csv')\n",
        "\n",
        "# Ensure both the patient_id and study_id in the labels file are strings\n",
        "label_coordinates_df['study_id'] = label_coordinates_df['study_id'].astype(str)\n",
        "\n",
        "# Define the root directory where DICOM files are stored\n",
        "dicom_root_dir = '/content/train_images/'\n",
        "\n",
        "# Step 1: Iterate through the DataFrame to dynamically load the DICOM files and annotate them\n",
        "for _, row in label_coordinates_df.iterrows():\n",
        "    study_id = row['study_id']\n",
        "    series_id = row['series_id']\n",
        "    instance_number = row['instance_number']\n",
        "\n",
        "    # Construct the DICOM file path\n",
        "    dicom_folder = os.path.join(dicom_root_dir, study_id, str(series_id))\n",
        "    dicom_file = f\"{instance_number}.dcm\"\n",
        "    dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "    # Check if the DICOM file exists\n",
        "    if os.path.exists(dicom_path):\n",
        "        # Load the DICOM file\n",
        "        dicom_image = pydicom.dcmread(dicom_path)\n",
        "\n",
        "        # Extract patient ID from DICOM (optional)\n",
        "        patient_id = dicom_image.PatientID\n",
        "\n",
        "        # Extract the coordinates and condition\n",
        "        x, y = int(row['x']), int(row['y'])\n",
        "        condition = row['condition']\n",
        "        level = row['level']\n",
        "\n",
        "        # Step 2: Annotate the DICOM image with bounding boxes and labels\n",
        "        pixel_array = dicom_image.pixel_array\n",
        "        normalized_image = cv2.normalize(pixel_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "        colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Draw a circle around the anomaly\n",
        "        cv2.circle(colored_image, (x, y), 10, (0, 255, 0), 2)\n",
        "\n",
        "        # Annotate the condition and level\n",
        "        label_text = f\"{condition} {level}\"\n",
        "        cv2.putText(colored_image, label_text, (x + 15, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "        # Step 3: Display the annotated image\n",
        "        plt.imshow(colored_image, cmap='gray')\n",
        "        plt.title(f\"Annotated DICOM Image for Study ID: {study_id}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Optionally, save the annotated image\n",
        "        output_path = f'annotated_dicom_image_{study_id}_{series_id}_{instance_number}.png'\n",
        "        cv2.imwrite(output_path, colored_image)\n",
        "    else:\n",
        "        print(f\"DICOM file not found: {dicom_path}\")\n"
      ],
      "metadata": {
        "id": "FiIerjUyHRPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Coordinates with Image Dimensions"
      ],
      "metadata": {
        "id": "xKVF1xcNICy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = dicom_image.pixel_array.shape\n",
        "if not (0 <= x < width and 0 <= y < height):\n",
        "    print(f\"Warning: Coordinates ({x}, {y}) are outside the image bounds for study {study_id}.\")\n"
      ],
      "metadata": {
        "id": "Cu8U7AwCIGtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Coordinates on the Original Image"
      ],
      "metadata": {
        "id": "k6_PzduMIQ4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Original DICOM image\n",
        "axes[0].imshow(dicom_image.pixel_array, cmap='gray')\n",
        "axes[0].set_title(f\"Original Image for {study_id}\")\n",
        "\n",
        "# Annotated image with coordinates\n",
        "axes[1].imshow(colored_image, cmap='gray')\n",
        "axes[1].set_title(f\"Annotated Image for {study_id}\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eyN5bCtSIRUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate Against Known Landmarks"
      ],
      "metadata": {
        "id": "a1MJWKWcIavQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example code to validate extracted coordinates\n",
        "height, width = dicom_image.pixel_array.shape\n",
        "\n",
        "# Check if coordinates are within bounds\n",
        "if 0 <= x < width and 0 <= y < height:\n",
        "    print(f\"Coordinates ({x}, {y}) are valid within the image bounds.\")\n",
        "else:\n",
        "    print(f\"Warning: Coordinates ({x}, {y}) are out of bounds for image of size ({width}, {height}).\")\n",
        "\n",
        "# Optional: Draw a reference box around the center of the image for validation purposes\n",
        "center_x, center_y = width // 2, height // 2\n",
        "cv2.rectangle(colored_image, (center_x - 50, center_y - 50), (center_x + 50, center_y + 50), (255, 0, 0), 2)\n",
        "\n",
        "# Display both the original and annotated images side by side for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "axes[0].imshow(dicom_image.pixel_array, cmap='gray')\n",
        "axes[0].set_title(\"Original Image\")\n",
        "\n",
        "axes[1].imshow(colored_image, cmap='gray')\n",
        "axes[1].set_title(\"Annotated Image with Validated Coordinates\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N_MY43nrIbP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bOVzL1crI729"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O7QUDa5LI7mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV files\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "series_descriptions_df = pd.read_csv('/content/train_series_descriptions.csv')\n",
        "label_coordinates_df = pd.read_csv('/content/train_label_coordinates.csv')\n",
        "\n",
        "# Ensure both the patient_id and study_id in the labels file are strings\n",
        "label_coordinates_df['study_id'] = label_coordinates_df['study_id'].astype(str)\n",
        "\n",
        "# Define the root directory where DICOM files are stored\n",
        "dicom_root_dir = '/content/train_images/'\n",
        "\n",
        "# Define the output directory for annotated images\n",
        "output_dir = '/content/annotated_images/'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Step 1: Iterate through the DataFrame to dynamically load the DICOM files and annotate them\n",
        "for study_id in label_coordinates_df['study_id'].unique():\n",
        "    study_data = label_coordinates_df[label_coordinates_df['study_id'] == study_id]\n",
        "\n",
        "    for series_id, series_data in study_data.groupby('series_id'):\n",
        "        for instance_number in series_data['instance_number'].unique():\n",
        "            dicom_folder = os.path.join(dicom_root_dir, study_id, str(series_id))\n",
        "            dicom_file = f\"{instance_number}.dcm\"\n",
        "            dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "            # Check if the DICOM file exists\n",
        "            if os.path.exists(dicom_path):\n",
        "                # Load the DICOM file\n",
        "                dicom_image = pydicom.dcmread(dicom_path)\n",
        "\n",
        "                # Extract the pixel data and normalize the image\n",
        "                pixel_array = dicom_image.pixel_array\n",
        "                normalized_image = cv2.normalize(pixel_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "                colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "                # Step 2: Iterate through all the labels for this instance_number\n",
        "                instance_data = series_data[series_data['instance_number'] == instance_number]\n",
        "                for _, row in instance_data.iterrows():\n",
        "                    # Extract coordinates and labels\n",
        "                    x, y = int(row['x']), int(row['y'])\n",
        "                    condition = row['condition']\n",
        "                    level = row['level']\n",
        "\n",
        "                    # Draw a circle around the anomaly\n",
        "                    cv2.circle(colored_image, (x, y), 10, (0, 255, 0), 2)\n",
        "\n",
        "                    # Annotate the condition and level\n",
        "                    label_text = f\"{condition} {level}\"\n",
        "                    cv2.putText(colored_image, label_text, (x + 15, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "                # Step 3: Display the annotated image\n",
        "                plt.imshow(colored_image, cmap='gray')\n",
        "                plt.title(f\"Annotated DICOM Image for Study ID: {study_id}, Series ID: {series_id}, Instance: {instance_number}\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "                # Step 4: Save the annotated image in the separate folder\n",
        "                output_path = os.path.join(output_dir, f'annotated_dicom_image_{study_id}_{series_id}_{instance_number}.png')\n",
        "                cv2.imwrite(output_path, colored_image)\n",
        "            else:\n",
        "                print(f\"DICOM file not found: {dicom_path}\")\n"
      ],
      "metadata": {
        "id": "OjbZ6zRKI8-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pGCHbS0qQ-HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Load and preprocess DICOM images\n",
        "def load_and_preprocess_dicom(dicom_path, target_size=(224, 224)):\n",
        "    # Load DICOM file\n",
        "    dicom_image = pydicom.dcmread(dicom_path)\n",
        "    pixel_array = dicom_image.pixel_array\n",
        "\n",
        "    # Normalize the pixel values to 0-255\n",
        "    normalized_image = cv2.normalize(pixel_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    # Convert grayscale to 3 channels (since ResNet expects 3-channel input)\n",
        "    colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    resized_image = cv2.resize(colored_image, target_size)\n",
        "\n",
        "    return resized_image\n",
        "\n",
        "# Step 2: Load the CSV files containing labels\n",
        "labels_df = pd.read_csv('/content/train.csv')  # Replace with actual path\n",
        "\n",
        "# Prepare labels (you need to decide the task: classification, regression, etc.)\n",
        "# For simplicity, let's assume a binary classification based on one of the conditions\n",
        "labels_df['label'] = labels_df['spinal_canal_stenosis_l1_l2'].apply(lambda x: 1 if x != 'Normal/Mild' else 0)\n",
        "\n",
        "# Step 3: Load ResNet50 Pre-trained model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Step 4: Add custom layers on top of the pre-trained ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)  # Add a fully connected layer\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Step 5: Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Step 6: Freeze the layers of ResNet50 to keep the pre-trained weights\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Create a generator to load images in batches\n",
        "# Prepare image data generator\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Normalizing images\n",
        "\n",
        "def data_generator(df, batch_size, target_size):\n",
        "    while True:\n",
        "        for start in range(0, len(df), batch_size):\n",
        "            end = min(start + batch_size, len(df))\n",
        "            batch_df = df[start:end]\n",
        "\n",
        "            images = []\n",
        "            labels = []\n",
        "            for _, row in batch_df.iterrows():\n",
        "                dicom_path = f\"/content/train_images/{row['study_id']}/{row['series_id']}/{row['instance_number']}.dcm\"  # Adjust as necessary\n",
        "                if os.path.exists(dicom_path):\n",
        "                    image = load_and_preprocess_dicom(dicom_path, target_size)\n",
        "                    images.append(image)\n",
        "                    labels.append(row['label'])\n",
        "\n",
        "            yield np.array(images), np.array(labels)\n",
        "\n",
        "# Step 8: Train the model using the generator\n",
        "batch_size = 16\n",
        "train_gen = data_generator(labels_df, batch_size=batch_size, target_size=(224, 224))\n",
        "\n",
        "# Train the model (adjust steps_per_epoch and validation_split as needed)\n",
        "model.fit(train_gen, epochs=10, steps_per_epoch=len(labels_df) // batch_size)\n",
        "\n",
        "# Step 9: Save the model\n",
        "model.save(\"resnet50_finetuned_dicom.h5\")\n"
      ],
      "metadata": {
        "id": "Qn-iRWE2Q9Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_df.columns)\n"
      ],
      "metadata": {
        "id": "xFNpX3PeWQ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV files\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "label_coordinates_df = pd.read_csv('/content/train_label_coordinates.csv')\n",
        "\n",
        "# Ensure both the patient_id and study_id in the labels file are strings\n",
        "label_coordinates_df['study_id'] = label_coordinates_df['study_id'].astype(str)\n",
        "\n",
        "# Define the root directory where DICOM files are stored\n",
        "dicom_root_dir = '/content/train_images/'\n",
        "\n",
        "# Define the output directory for annotated images\n",
        "output_dir = '/content/annotated_images/'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Step 1: Iterate through the DataFrame to dynamically load the DICOM files and annotate them\n",
        "for study_id in label_coordinates_df['study_id'].unique():\n",
        "    study_data = label_coordinates_df[label_coordinates_df['study_id'] == study_id]\n",
        "\n",
        "    for instance_number in study_data['instance_number'].unique():\n",
        "        dicom_folder = os.path.join(dicom_root_dir, study_id)\n",
        "        dicom_file = f\"{instance_number}.dcm\"\n",
        "        dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "        # Check if the DICOM file exists\n",
        "        if os.path.exists(dicom_path):\n",
        "            # Load the DICOM file\n",
        "            dicom_image = pydicom.dcmread(dicom_path)\n",
        "\n",
        "            # Extract the pixel data and normalize the image\n",
        "            pixel_array = dicom_image.pixel_array\n",
        "            normalized_image = cv2.normalize(pixel_array, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "            colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Step 2: Iterate through all the labels for this instance_number\n",
        "            instance_data = study_data[study_data['instance_number'] == instance_number]\n",
        "            for _, row in instance_data.iterrows():\n",
        "                # Extract coordinates and labels\n",
        "                x, y = int(row['x']), int(row['y'])\n",
        "                condition = row['condition']\n",
        "                level = row['level']\n",
        "\n",
        "                # Draw a circle around the anomaly\n",
        "                cv2.circle(colored_image, (x, y), 10, (0, 255, 0), 2)\n",
        "\n",
        "                # Annotate the condition and level\n",
        "                label_text = f\"{condition} {level}\"\n",
        "                cv2.putText(colored_image, label_text, (x + 15, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "            # Step 3: Display the annotated image\n",
        "            plt.imshow(colored_image, cmap='gray')\n",
        "            plt.title(f\"Annotated DICOM Image for Study ID: {study_id}, Instance: {instance_number}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Step 4: Save the annotated image in the separate folder\n",
        "            output_path = os.path.join(output_dir, f'annotated_dicom_image_{study_id}_{instance_number}.png')\n",
        "            cv2.imwrite(output_path, colored_image)\n",
        "        else:\n",
        "            print(f\"DICOM file not found: {dicom_path}\")\n"
      ],
      "metadata": {
        "id": "gNkflYyAWuvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "new attempt\n"
      ],
      "metadata": {
        "id": "vItooEb1ZE72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Load and preprocess DICOM images\n",
        "def load_dicom(dicom_path):\n",
        "    dicom_image = pydicom.dcmread(dicom_path)\n",
        "    pixel_array = dicom_image.pixel_array\n",
        "    return pixel_array\n",
        "\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    image = image.astype(np.float32) / np.max(image)\n",
        "    # Resize the image\n",
        "    image = cv2.resize(image, target_size)\n",
        "    # Convert grayscale to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    return image\n",
        "\n",
        "# Load CSV data\n",
        "label_coordinates_df = pd.read_csv('/content/train_label_coordinates.csv')\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "series_descriptions_df = pd.read_csv('/content/train_series_descriptions.csv')\n",
        "\n",
        "# Merge the data if necessary (using study_id)\n",
        "merged_df = pd.merge(label_coordinates_df, labels_df, on='study_id')\n",
        "merged_df = pd.merge(merged_df, series_descriptions_df, on=['study_id', 'series_id'])\n",
        "\n",
        "# Prepare X (images) and y (labels)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Step 2: Iterate through the DataFrame, load DICOM images, preprocess them, and prepare the labels\n",
        "dicom_root_dir = '/content/train_images/'  # Define the root directory of DICOM files\n",
        "\n",
        "for _, row in merged_df.iterrows():\n",
        "    study_id = row['study_id']\n",
        "    series_id = row['series_id']\n",
        "    instance_number = row['instance_number']  # Assuming this exists in label_coordinates_df\n",
        "    dicom_folder = os.path.join(dicom_root_dir, str(study_id), str(series_id))\n",
        "    dicom_file = f\"{instance_number}.dcm\"\n",
        "    dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "    # Load and preprocess the DICOM image\n",
        "    if os.path.exists(dicom_path):\n",
        "        image = load_dicom(dicom_path)\n",
        "        image = preprocess_image(image)\n",
        "        X.append(image)\n",
        "\n",
        "        # Assuming the label is binary (you can adjust based on your task)\n",
        "        label = 1 if row['spinal_canal_stenosis_l1_l2'] != 'Normal/Mild' else 0\n",
        "        y.append(label)\n",
        "\n",
        "# Convert X and y to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Step 3: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Load ResNet50 Pre-trained model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top of the pre-trained ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)  # Add a fully connected layer\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Step 5: Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the ResNet50 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 6: Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)\n",
        "\n",
        "# Step 7: Save the model\n",
        "model.save(\"resnet50_finetuned_dicom.h5\")\n"
      ],
      "metadata": {
        "id": "559V_Y0WZEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AJTJMBEtbnhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg\n",
        "!pip install pylibjpeg-rle\n",
        "\n"
      ],
      "metadata": {
        "id": "1wGhkUH5b0rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Load and preprocess DICOM images\n",
        "def load_dicom(dicom_path):\n",
        "    dicom_image = pydicom.dcmread(dicom_path)\n",
        "    pixel_array = dicom_image.pixel_array\n",
        "    return pixel_array\n",
        "\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    image = image.astype(np.float32) / np.max(image)\n",
        "    # Resize the image\n",
        "    image = cv2.resize(image, target_size)\n",
        "    # Convert grayscale to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    return image\n",
        "\n",
        "# Load CSV data\n",
        "label_coordinates_df = pd.read_csv('/content/train_label_coordinates.csv')\n",
        "labels_df = pd.read_csv('/content/train.csv')\n",
        "series_descriptions_df = pd.read_csv('/content/train_series_descriptions.csv')\n",
        "\n",
        "# Merge the data if necessary (using study_id)\n",
        "merged_df = pd.merge(label_coordinates_df, labels_df, on='study_id')\n",
        "merged_df = pd.merge(merged_df, series_descriptions_df, on=['study_id', 'series_id'])\n",
        "\n",
        "# Step 2: Sample a subset of the data\n",
        "sample_size = 100  # Adjust this to use the desired number of samples\n",
        "subset_df = merged_df.sample(n=sample_size, random_state=42)  # Randomly select n samples\n",
        "\n",
        "# Prepare X (images) and y (labels)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Step 3: Iterate through the sampled DataFrame, load DICOM images, preprocess them, and prepare the labels\n",
        "dicom_root_dir = '/content/train_images/'  # Define the root directory of DICOM files\n",
        "\n",
        "for _, row in subset_df.iterrows():\n",
        "    study_id = row['study_id']\n",
        "    series_id = row['series_id']\n",
        "    instance_number = row['instance_number']  # Assuming this exists in label_coordinates_df\n",
        "    dicom_folder = os.path.join(dicom_root_dir, str(study_id), str(series_id))\n",
        "    dicom_file = f\"{instance_number}.dcm\"\n",
        "    dicom_path = os.path.join(dicom_folder, dicom_file)\n",
        "\n",
        "    # Load and preprocess the DICOM image\n",
        "    if os.path.exists(dicom_path):\n",
        "        image = load_dicom(dicom_path)\n",
        "        image = preprocess_image(image)\n",
        "        X.append(image)\n",
        "\n",
        "        # Assuming the label is binary (you can adjust based on your task)\n",
        "        label = 1 if row['spinal_canal_stenosis_l1_l2'] != 'Normal/Mild' else 0\n",
        "        y.append(label)\n",
        "\n",
        "# Convert X and y to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Step 4: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Load ResNet50 Pre-trained model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top of the pre-trained ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)  # Add a fully connected layer\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Step 6: Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the ResNet50 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the model with the subset of data\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)\n",
        "\n",
        "# Step 8: Save the model\n",
        "model.save(\"resnet50_finetuned_dicom.h5\")\n"
      ],
      "metadata": {
        "id": "ecr0yhWZbn2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}